{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 5, 7, 8, 4, 3, 9], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/mlflow/mlflow/master/examples/sklearn_elasticnet_wine/wine-quality.csv\")\n",
    "data[\"quality\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Paarth\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mlflow\\types\\utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = data.drop('quality', axis=1)\n",
    "y = data['quality']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "signature = infer_signature(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "def build_ann_model(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Paarth\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 41.5198 - mean_squared_error: 41.5198 - val_loss: 2.6356 - val_mean_squared_error: 2.6356\n",
      "Epoch 2/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5191 - mean_squared_error: 1.5191 - val_loss: 0.7857 - val_mean_squared_error: 0.7857\n",
      "Epoch 3/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7569 - mean_squared_error: 0.7569 - val_loss: 0.6958 - val_mean_squared_error: 0.6958\n",
      "Epoch 4/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6352 - mean_squared_error: 0.6352 - val_loss: 0.6657 - val_mean_squared_error: 0.6657\n",
      "Epoch 5/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6753 - mean_squared_error: 0.6753 - val_loss: 0.6537 - val_mean_squared_error: 0.6537\n",
      "Epoch 6/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7006 - mean_squared_error: 0.7006 - val_loss: 0.6423 - val_mean_squared_error: 0.6423\n",
      "Epoch 7/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6359 - mean_squared_error: 0.6359 - val_loss: 0.8040 - val_mean_squared_error: 0.8040\n",
      "Epoch 8/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6628 - mean_squared_error: 0.6628 - val_loss: 0.6723 - val_mean_squared_error: 0.6723\n",
      "Epoch 9/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6610 - mean_squared_error: 0.6610 - val_loss: 0.8593 - val_mean_squared_error: 0.8593\n",
      "Epoch 10/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6536 - mean_squared_error: 0.6536 - val_loss: 0.6269 - val_mean_squared_error: 0.6269\n",
      "Epoch 11/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6346 - mean_squared_error: 0.6346 - val_loss: 0.7257 - val_mean_squared_error: 0.7257\n",
      "Epoch 12/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6642 - mean_squared_error: 0.6642 - val_loss: 0.7442 - val_mean_squared_error: 0.7442\n",
      "Epoch 13/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6012 - mean_squared_error: 0.6012 - val_loss: 0.7226 - val_mean_squared_error: 0.7226\n",
      "Epoch 14/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7222 - mean_squared_error: 0.7222 - val_loss: 0.6315 - val_mean_squared_error: 0.6315\n",
      "Epoch 15/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6332 - mean_squared_error: 0.6332 - val_loss: 0.6107 - val_mean_squared_error: 0.6107\n",
      "Epoch 16/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6285 - mean_squared_error: 0.6285 - val_loss: 0.7173 - val_mean_squared_error: 0.7173\n",
      "Epoch 17/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6359 - mean_squared_error: 0.6359 - val_loss: 0.6076 - val_mean_squared_error: 0.6076\n",
      "Epoch 18/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6697 - mean_squared_error: 0.6697 - val_loss: 0.6161 - val_mean_squared_error: 0.6161\n",
      "Epoch 19/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6079 - mean_squared_error: 0.6079 - val_loss: 0.9117 - val_mean_squared_error: 0.9117\n",
      "Epoch 20/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7755 - mean_squared_error: 0.7755 - val_loss: 0.6032 - val_mean_squared_error: 0.6032\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (2654783836.py, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[24], line 23\u001b[1;36m\u001b[0m\n\u001b[1;33m    return {\"loss\": model.evaluate(X_test_scaled, y_test)[1], \"status\": STATUS_OK}\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "model=build_ann_model(X_train_scaled.shape[1])\n",
    "model.compile(optimizer='adam', \n",
    "                loss='mean_squared_error',\n",
    "                metrics=['mean_squared_error'])\n",
    "with mlflow.start_run:\n",
    "    model.fit(X_train_scaled, y_train, epochs=20, batch_size=32, validation_data=(X_test_scaled, y_test),verbose=0)\n",
    "    mlflow.keras.log_model(model, \"model\", signature=signature)\n",
    "    mlflow.log_metric(\"mse\", model.evaluate(X_test_scaled, y_test)[1])\n",
    "    mlflow.log_param(\"epochs\", 20)\n",
    "    mlflow.log_param(\"batch_size\", 32)\n",
    "    mlflow.log_param(\"layers\", 2)\n",
    "    mlflow.log_param(\"units\", 64)\n",
    "    mlflow.log_param(\"activation\", \"relu\")\n",
    "    mlflow.log_param(\"loss\", \"mean_squared_error\")\n",
    "    mlflow.log_param(\"optimizer\", \"adam\")\n",
    "    mlflow.log_param(\"metrics\", \"mean_squared_error\")\n",
    "    mlflow.log_param(\"input_dim\", X_train_scaled.shape[1])\n",
    "    mlflow.log_param(\"output_dim\", 1)\n",
    "\n",
    "    mlflow.keras.log_model(model, \"model\", signature=signature)\n",
    "    return {\"loss\": model.evaluate(X_test_scaled, y_test)[1], \"status\": STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
